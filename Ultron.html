<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta content="IE=edge" http-equiv="X-UA-Compatible">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <meta content="Ultron AI Chatbot - Fine-tuned Mistral-7B with QLoRA, voice interface, and optimized 4-bit quantization" name="description">
  <meta name="google" content="notranslate" />
  <meta content="Mashup templates have been developed by Orson.io team" name="author">

  <!-- Disable tap highlight on IE -->
  <meta name="msapplication-tap-highlight" content="no">

  <link rel="apple-touch-icon" sizes="180x180" href="./assets/apple-icon-180x180.png">
  <link href="./assets/favicon.ico" rel="icon">

  <title>Ultron AI Chatbot - Kacper Kowalski</title>
  <link href="./main.d8e0d294.css" rel="stylesheet">
  
  <style>
    /* Standardized image sizing for consistency */
    .project-img {
      width: 100%;
      max-width: 800px;
      height: auto;
      display: block;
      margin: 15px auto;
      border-radius: 6px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      transition: transform 0.3s ease;
    }
    
    .project-img:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
    }
    
    .white-card {
      margin-bottom: 30px;
      border-radius: 6px;
    }
    
    .white-card img {
      width: 100%;
      max-width: 800px;
      height: auto;
      margin: 0 auto;
      display: block;
      border-radius: 6px;
    }
    
    .card-block {
      padding: 25px;
    }
    
    h2 {
      margin-top: 0;
      margin-bottom: 25px;
      color: #333;
    }
  </style>
</head>

<body>

  <main class="content-wrapper">
    <header class="white-text-container section-container">
      <div class="text-center">
        <h1 style="color: white; text-align: center;">Ultron AI Character Chatbot</h1>
      </div>
    </header>

    <div class="card white-card">
      <img src="./assets/images/ultron/Ultron Main.jpg" alt="Ultron AI chatbot terminal interface" class="project-img">
    </div>

    <div class="card white-card">
      <img src="./assets/images/ultron/Ultron Startup.png" alt="Ultron AI model loading and initialization" class="project-img">
      <p style="color: black; text-align: center;">Model Loading - 4-bit quantization initialization on NVIDIA RTX 4060 Ti</p>
    </div>

    <div class="card">
      <div class="card-block">
        <h2 style="color: black; text-align: center;">About the Project</h2>
        <h4 class="h5">Technologies: Python, Mistral-7B, QLoRA, PyTorch, Transformers, pyttsx3, Speech Recognition</h4>
        
        <p style="text-align: center; margin-bottom: 20px;">
          <a href="https://github.com/Kapi1243/Ultron-Chatbot" class="btn btn-primary" target="_blank">
            <i class="fa fa-github"></i> View Code on GitHub
          </a>
        </p>

        <h4 class="h5">üéØ Project Overview:</h4>
        <p>A state-of-the-art AI character implementation featuring Ultron from Marvel's Avengers, built with professional software architecture, advanced optimization, and voice capabilities. This project showcases AI engineering skills through fine-tuned large language models, memory-efficient training techniques, and production-ready system design.</p>
        
        <p><strong>Note:</strong> This is a command-line interface (CLI) application focused on AI/ML engineering excellence rather than front-end development. The terminal-based interface demonstrates core competencies in natural language processing, model optimization, and voice AI integration. A web-based UI is planned for future releases (see Future Enhancements below).</p>

        <h4 class="h5">üìä Performance Metrics:</h4>
        <ul>
          <li><strong>Model Architecture:</strong> Mistral-7B-Instruct-v0.2 (7 billion parameters) with LoRA fine-tuning</li>
          <li><strong>Memory Efficiency:</strong> 4-bit quantization reduces VRAM usage by 75% (~4GB vs 16GB)</li>
          <li><strong>Model Load Time:</strong> 15-30 seconds on NVIDIA RTX 4060 Ti (8GB VRAM)</li>
          <li><strong>Average Response Time:</strong> 2-5 seconds per generation</li>
          <li><strong>Throughput:</strong> 5-10 tokens per second</li>
          <li><strong>Test Coverage:</strong> >90% for core modules</li>
        </ul>

        <h4 class="h5">üÜö Performance Comparison & Optimization Impact:</h4>
        <ul>
          <li><strong>Base Model vs Fine-tuned Performance:</strong>
            <ul>
              <li>Character Consistency: Base Mistral-7B frequently breaks character and gives generic responses. Fine-tuned Ultron model maintains character voice and personality throughout conversations</li>
              <li>Response Relevance: Fine-tuning on character-specific dialogue improved on-topic responses and reduced off-character behavior</li>
              <li>Tone Accuracy: Custom personality module ensures antagonistic, philosophical tone matching Ultron's character from source material</li>
            </ul>
          </li>
          <li><strong>Quantization Impact:</strong>
            <ul>
              <li>Full Precision (FP16): 16GB VRAM required, baseline inference speed</li>
              <li>4-bit Quantization: 4GB VRAM (75% reduction), enables deployment on consumer GPUs</li>
              <li>Quality Trade-off: Minimal quality degradation - responses remain coherent and character-consistent</li>
            </ul>
          </li>
          <li><strong>Optimization Stack Results:</strong>
            <ul>
              <li>Baseline inference: ~8 seconds per response</li>
              <li>+ Mixed Precision (FP16): ~6.4 seconds (20% improvement)</li>
              <li>+ Response Caching: ~3.2 seconds for repeated queries (50% additional reduction)</li>
              <li>+ Model Compilation: ~2.8 seconds (10-15% final boost)</li>
              <li>Final: 2-5 second range depending on prompt complexity and cache hits</li>
            </ul>
          </li>
        </ul>

        <h4 class="h5">‚ú® Key Features:</h4>
        
        <p><strong>üß† Advanced AI Capabilities:</strong></p>
        <ul>
          <li><strong>QLoRA Fine-tuning:</strong> Memory-efficient training with 4-bit quantization for authentic Ultron personality</li>
          <li><strong>Response Caching:</strong> LRU cache system provides 50% faster responses for repeated queries</li>
          <li><strong>Mixed Precision:</strong> Automatic FP16 inference optimization for 20% speed improvement</li>
          <li><strong>Smart Memory Management:</strong> Auto-cleanup and CUDA optimization prevents out-of-memory errors</li>
          <li><strong>Conversation Context:</strong> Multi-turn dialogue with personality consistency across interactions</li>
          <li><strong>Model Compilation:</strong> PyTorch 2.0 optimization for 10-15% additional speedup</li>
        </ul>

        <p><strong>üé§ Voice Interface:</strong></p>
        <ul>
          <li><strong>Push-to-Talk:</strong> Space bar activation for seamless voice input</li>
          <li><strong>Text-to-Speech:</strong> Optimized voice selection for character immersion with pitch/tone adjustments</li>
          <li><strong>Fallback Support:</strong> Automatic text input when audio unavailable</li>
          <li><strong>Noise Handling:</strong> Dynamic energy threshold adjustment for reliable speech recognition</li>
          <li><strong>Audio Effects:</strong> FFmpeg processing for metallic voice characteristics (pitch shift, filters, echo)</li>
        </ul>

        <p><strong>üèóÔ∏è Professional Architecture:</strong></p>
        <ul>
          <li><strong>Modular Design:</strong> Clean separation of concerns (Model, Audio, Personality modules)</li>
          <li><strong>Error Handling:</strong> Comprehensive exception management with graceful degradation</li>
          <li><strong>Performance Monitoring:</strong> Real-time metrics tracking and GPU memory monitoring</li>
          <li><strong>Structured Logging:</strong> Configurable logging levels for debugging and production</li>
          <li><strong>Configuration Management:</strong> Layered config system (defaults ‚Üí file ‚Üí CLI ‚Üí environment)</li>
        </ul>

        <h4 class="h5">üîß Technical Implementation:</h4>
        
        <p><strong>Model Optimization:</strong></p>
        <ul>
          <li>4-bit NF4 quantization with double quantization for extreme memory efficiency</li>
          <li>LoRA adapters for parameter-efficient fine-tuning (trains <1% of parameters)</li>
          <li>BitsAndBytes integration for optimized 4-bit operations</li>
          <li>PEFT (Parameter-Efficient Fine-Tuning) library for adapter management</li>
          <li>Automated device mapping for multi-GPU support</li>
        </ul>

        <p><strong>Core Components:</strong></p>
        <ul>
          <li><strong>UltronModel:</strong> Optimized model loading with quantization, cached inference, performance monitoring</li>
          <li><strong>AudioManager:</strong> Modular TTS/STT engines with fallback support, push-to-talk functionality, voice optimization</li>
          <li><strong>UltronPersonality:</strong> Character-consistent prompt engineering, response post-processing, quality assessment</li>
          <li><strong>Config System:</strong> Environment-based configuration with CLI override support</li>
        </ul>

        <p><strong>Software Engineering:</strong></p>
        <ul>
          <li>SOLID principles and dependency injection pattern</li>
          <li>Comprehensive docstrings and type hints throughout</li>
          <li>Unit, integration, and performance test suites</li>
          <li>Docker containerization for consistent deployment</li>
          <li>Multi-cloud deployment guides (AWS, GCP, Azure)</li>
        </ul>

        <h4 class="h5">üöÄ Usage & Configuration:</h4>
        
        <p><strong>Basic Interaction:</strong></p>
        <ul>
          <li>Hold SPACE to speak or type messages directly</li>
          <li>Say "exit" or "quit" to terminate conversation</li>
          <li>Type "stats" for real-time performance metrics</li>
          <li>Type "clear" to reset conversation history</li>
        </ul>

        <p><strong>Configuration Options:</strong></p>
        <ul>
          <li><code>load_in_4bit</code>: Enable 4-bit quantization for ~4GB VRAM usage</li>
          <li><code>device_map</code>: GPU assignment ({"": 0} for single GPU)</li>
          <li><code>max_new_tokens</code>: Response length limit (default: 150)</li>
          <li><code>temperature</code>: Response creativity (0.7-0.9 range)</li>
          <li><code>top_p</code>: Nucleus sampling threshold (0.9 recommended)</li>
        </ul>

        <h4 class="h5">üí° Challenges & Solutions:</h4>
        <ul>
          <li><strong>GPU Memory Constraints:</strong> 7B parameter model requires 28GB+ VRAM in full precision. Solved by implementing 4-bit quantization with QLoRA, reducing memory footprint by 75% to run on 8GB consumer GPUs while maintaining quality.</li>
          <li><strong>Character Consistency:</strong> Maintaining Ultron's personality across conversations was challenging. Solved by fine-tuning with LoRA adapters on curated dialogue, implementing advanced prompt engineering with few-shot examples, and post-processing responses for character voice.</li>
          <li><strong>Slow Inference Times:</strong> Initial response times exceeded 10 seconds. Solved by implementing LRU caching for repeated queries (50% speedup), mixed precision FP16 inference (20% improvement), model compilation with PyTorch 2.0 (15% gain), and batch processing optimization.</li>
          <li><strong>Voice System Reliability:</strong> Audio input/output failed in various environments. Solved by implementing fallback cascade (TTS ‚Üí text output), modular engine design allowing provider swapping, comprehensive error handling with graceful degradation, and audio system testing on startup.</li>
          <li><strong>Production Deployment:</strong> Moving from prototype to production-ready system required extensive refactoring. Solved by implementing clean architecture with dependency injection, comprehensive testing (>90% coverage), Docker containerization, multi-cloud deployment guides, and performance monitoring dashboards.</li>
        </ul>

        <h4 class="h5">üéì Learning Outcomes:</h4>
        <ul>
          <li><strong>Large Language Models:</strong> Fine-tuning, quantization, inference optimization</li>
          <li><strong>Memory Optimization:</strong> QLoRA, 4-bit quantization, mixed precision training</li>
          <li><strong>Production ML Systems:</strong> Caching strategies, performance monitoring, error handling</li>
          <li><strong>Character AI:</strong> Prompt engineering, personality consistency, response post-processing</li>
          <li><strong>Audio Processing:</strong> Speech-to-text, text-to-speech, audio effects with FFmpeg</li>
          <li><strong>Software Architecture:</strong> Modular design, dependency injection, configuration management</li>
          <li><strong>DevOps:</strong> Docker containerization, multi-cloud deployment, CI/CD readiness</li>
        </ul>

        <h4 class="h5">üîÆ Future Enhancements:</h4>
        <ul>
          <li><strong>Web UI:</strong> Real-time chat interface with WebSocket support</li>
          <li><strong>REST API:</strong> FastAPI endpoint for programmatic access</li>
          <li><strong>RAG Integration:</strong> Retrieval-Augmented Generation for dynamic knowledge</li>
          <li><strong>Multi-modal Input:</strong> Vision capabilities for image understanding</li>
          <li><strong>Conversation Persistence:</strong> Database integration for long-term memory</li>
          <li><strong>Model Ensemble:</strong> Multiple model support with voting/routing</li>
          <li><strong>A/B Testing Framework:</strong> Experimental features and performance comparison</li>
        </ul>

        <h4 class="h5">üèÜ Technical Highlights:</h4>
        <ul>
          <li>Successfully deployed 7B parameter LLM on consumer-grade GPU (8GB VRAM)</li>
          <li>Achieved production-grade performance with <5s response times</li>
          <li>Implemented memory-efficient training reducing requirements by 75%</li>
          <li>Built scalable architecture ready for microservices deployment</li>
          <li>Maintained >90% test coverage across all core modules</li>
          <li>Demonstrated clean code principles with comprehensive documentation</li>
        </ul>
      </div>
    </div>

    <div class="card white-card">
      <img src="./assets/images/ultron/Question1.png" alt="Ultron conversation example 1" class="project-img">
      <p style="color: black; text-align: center;">Conversation Example - Character personality demonstration</p>
    </div>

    <div class="card white-card">
      <img src="./assets/images/ultron/Question2.png" alt="Ultron conversation example 2" class="project-img">
      <p style="color: black; text-align: center;">Multi-turn Dialogue - Contextual conversation flow</p>
    </div>

    <div class="card white-card">
      <img src="./assets/images/ultron/Question3.png" alt="Ultron conversation example 3" class="project-img">
      <p style="color: black; text-align: center;">Response Quality - Fine-tuned personality responses</p>
    </div>

    <div class="card white-card">
      <img src="./assets/images/ultron/Question4.png" alt="Ultron conversation example 4" class="project-img">
      <p style="color: black; text-align: center;">Character Consistency - Authentic Ultron behavior</p>
    </div>

    <div class="card white-card">
      <img src="./assets/images/ultron/Question5.png" alt="Ultron conversation example 5" class="project-img">
      <p style="color: black; text-align: center;">Advanced Interaction - Complex dialogue handling</p>
    </div>

    <div class="card white-card">
      <h4 class="h5" style="color: black; text-align: center; margin-top: 20px;">Project Demonstration</h4>
      <p style="color: black; text-align: center;">This is a terminal-based application demonstrating AI/ML engineering capabilities.</p>
      <p style="color: black; text-align: center; margin-top: 15px;">
        <strong>Screenshots showcase:</strong><br>
        ‚úÖ Model initialization with 4-bit quantization<br>
        ‚úÖ Character personality and dialogue consistency<br>
        ‚úÖ Multi-turn conversation with context awareness<br>
        ‚úÖ Terminal-based interface optimized for performance<br>
        ‚úÖ Fine-tuned Mistral-7B responses as Ultron character
      </p>
      <p style="color: black; text-align: center; font-style: italic; margin-top: 15px;">Video demonstration with voice interaction coming soon</p>
      <a href="index.html" class="btn btn-secondary" style="text-align: center; margin-top: 20px;">Back to Projects</a>
    </div>
  </main>

</body>

</html>
